# 面试题
将见过的面试题和自己想到查到的回答

[1_训练加速](#1.训练加速)
- 数据并行
- 数据并行(nn.distributed) \[todo]
- 模型并行

[2_目标检测](#2.目标检测) 
- 1.算法有哪些？他们的对比？
    - RCNN：
    - fast RCNN
    - faster RCNN
    - YOLO
    - SSD
- 2.简述一下YOLOv2的原理，v1和v2有什么区别？
- 3.非极大抑制是什么，有什么作用？
- 4.如何实现mOU 和非极大抑制？

[3_循环卷积神经网络](#3.循环卷积神经网络) 
- 1.LSTM为什么会导致梯度爆炸？要如何解决？

[4_语义分割](#4.语义分割) 
- 1.主要语义分割的算法有哪些，他们有什么区别？
- 2.deeplabv3的核心是什么？
- 3.感受野会受到什么因素的影响？怎么影响？

[5_Backbone](#5.Backbone) 
- 1.resnet中的恒等快捷连接在前向传播和反向传播都有什么作用？

[6_卷积神经网络基础](#6.卷积神经网络基础)
- 1.Batch Normalization 在卷积神经网络中的作用是什么?
- 2.1*1卷积的作用是什么？
- 3.两层较小的卷积核和一个较大的卷积核比较，各有什么缺点和优点？
- 4.不同激活函数有什么区别？
- 5.卷积层输出大小的计算?
- 6.dropout层为什么可以促进正则化？
- 7.平方误差损失函数和交叉熵损失函数分别适用于什么场景？
- 8.梯度消失/爆炸的原因?
- 9.损失降不下来怎么办？
- 10.weight decay vs L2 正则项

[7_神经网络训练场景问题](#7.神经网络训练场景问题)
- 1.怎么判断过拟合，怎么处理？
- 2.怎么解决图像语义分割中的样本不均衡问题?

[8_Python](#8.Python)
- 1.装饰器是什么，有什么作用？
- 2.迭代器
- 3.生成器
  

## 1.训练加速
1. 使用多块GPU时要如何设置？

数据并行：
1. 将CUDA_VISIBLE_DEVICES设置成想要运行的几块卡
2. 使用nn.DataParallel函数将模型包起来，并传入指定的GPU
3. 将模型和数据都.cuda() 传入GPU

数据并行（nn.distributed）--需要有batchsize>1才可以
\# todo:nn.distribute

模型并行：

1. 将模型通过在模型定义的部分拆分到几块不同的显卡上
2. 在forward部分将数据传到对应的显卡并前传

## 2.目标检测
1. 算法有哪些？他们的对比？
主要算法有 rcnn（region-convnet）系列，SSD，Retina net，yolov1v2v3等，其中rcnn网络为两阶段网络，即将目标检测中的定位和识别任务分为两个步骤进行解决，缺点在于速度较慢，优点在于准确度较高
    1. RCNN：

        ![Pics/Untitled.png](../Pics/Untitled.png)

        首先使用selective search（评估图像相邻部分的相似度并将相似度高的部分合并并打分，选出评分较高的2000个子图）在原始图片中选择出子图；

        随后将提取出的子图进行warp，从而采用一个统一的大小，同样大小的子图输入特征提取网络（卷积-relu-池化-全连接）进行特征提取；

        根据每个子图提取的特征进行分类，保留某一类打分较高的区块，作为物体的最终定位区块

        它较慢的原因主要在于一张图片要提取2000个子图，每个子图都要做特征提取

    2. fast RCNN：
        - 

        ![https://img.mukewang.com/5b2bbbd6000129a213380536.jpg](https://img.mukewang.com/5b2bbbd6000129a213380536.jpg)

        - 引入ROI-pooling结构，在将图片warp的部分改为使用ROI pooling，因为特征提取网络中采用了全连接神经网络，因此传入全连接层的特征图大小必须一致，之前采用了对原始图片进行warp，这样容易使得图片产生形变和信息丢失，而且这个操作较费事，现在采用ROI pooling，即根据变换后图片的尺寸例如M*N，将特征图分为M*N个方格，并取出其中的最大值（最显著的特征），加快了操作
        - 提出多任务损失的思想，将分类损失和边框定位损失结合在一起统一训练
        - 将整图只通过一次CNN网络就提取所有ROI的特征。因为2000个子图在原图上有很多重叠，因此每个子图都通过一个特征提取网络是费时费力的，因此，通过区域投影的方式，将整图通过特征提取网络，再利用区域投影将整图的特征取出ROI的那一部分，即可通过一次特征提取网络，得到所有的ROI的特征
    3. faster RCNN：

        ![Pics/Untitled%201.png](../Pics/Untitled%201.png)

        这个部分的改进是将原本的ROI提取方法—selective search 改为了Region Proposal Network，这样大大增加了提取目标框的速度。RPN网络通过在原始卷积层上提取的特征经过进一步3*3卷积增加感受野，得到了提取ROI和调整ROI边界两个支路，

        在提取ROI支路上，基于之前在CONV5的特征图上每一个点生成的k个anchor，随后通过1*1卷积获得W*H*18的输出结果，这个结果代表每个点9个anchor，前景和背景的两个结果，随后通过reshape和softmax得到概率，区分目标是前景还是后景（这一步的判断是为了去除大量无用的背景anchor）；

        另一条通过1*1卷积reshape到36层的特征图是对应于bbox相对于原始anchor的偏移量，由于通过四个线性变换参数，anchor就可以变换中心点位置和长宽，从而变换到接近到GT的bbox坐标，因此通过原始特征图变换就可以得到这四个参数，由于每个点有9个anchor，同时每个anchor需要四个参数调整位置，因此这一层的输出有36层；

        回到图，VGG输出50*38*512的特征，对应设置50*38*k个anchors，而RPN输出：

        1. 大小为50*38*2k 的positive/negative softmax分类特征矩阵
        2. 大小为50*38*4k的regression坐标回归特征矩阵

        最后proposal层综合主要的前景anchors和对应的偏移量结合NMS和一些筛选方法获取proposal；

        其实RPN最终就是在原图尺度上，设置了密密麻麻的候选Anchor。然后用cnn去判断哪些Anchor是里面有目标的positive anchor，哪些是没目标的negative anchor。所以，仅仅是个二分类而已！

        特征图生成anchor，anchor长宽和中心点变换，anchor NMS筛选

        随后，这些proposals 通过ROI pooling层用于后续的ROI大小统一，并用于分类操作，分类后的ROI还需要进一步调整bbox的大小。

    4. YOLO

        ![Pics/Untitled%202.png](../Pics/Untitled%202.png)

        在网络结构上，YOLO分为三个部分，第一个部分是特征提取网络，用于提取有用的可泛化的特征，第二部分为目标检测网络，在目标检测网络之后，就获得了7*7*30的输出结果，这个部分相当于将原图分为了7*7的网格，每个网格预测两个长宽不同的anchor的位置和长宽，以及这两个anchor的置信分数（是否有目标*和真实bbox的IOU）以及这个格子内的物体属于哪一个类别。

        将原图划分成S*S大小的格子，每个格子用于预测中心点落在格子内的目标。
                每个各自预测B个边界框和他们对应的置信度（置信度是边界框中有目标的概率*这个边界框的准确度，用IOU来衡量）。
                而为了表示边界框，需要使用（x,y,w,h）表示，结合上置信度，则每个边界框预测（x,y,w,h,c）。
                除此之外，对于每个格子会预测一组条件类别概率C，因此每个格子会产生（B*5+C）大小的向量，总共就是（S*S,B*5+C）

        ![Pics/Untitled%203.png](../Pics/Untitled%203.png)

        损失函数中，使用了MSEloss，对于不同类别的误差采取了系数进行调控。

        yolo算法开创了one-stage检测的先河，它将物体分类和物体检测网络合二为一，都在全连接层完成。故它大大降低了目标检测的耗时，提高了实时性。但它的缺点也十分明显

        1. 每个网格只对应两个bounding box，当物体的长宽比不常见（也就是训练数据集覆盖不到时），效果很差。
        2. 原始图片只划分为7x7的网格，当两个物体靠的很近时，效果很差
        3. 最终每个网格只对应一个类别，容易出现漏检（物体没有被识别到）。
        4. 对于图片中比较小的物体，效果很差。这其实是所有目标检测算法的通病，SSD对它有些优化，我们后面再看。
    5. SSD Single Shot MultiBox Detector

        ![Pics/Untitled%204.png](../Pics/Untitled%204.png)

        相比Yolo，SSD采用CNN来直接进行检测，而不是像Yolo那样在全连接层之后做检测。SSD提取了不同尺度的特征图来做检测，大尺度特征图（较靠前的特征图）可以用来检测小物体，而小尺度特征图（较靠后的特征图）用来检测大物体；

        SSD采用了不同尺度和长宽比的先验框（Prior boxes, Default boxes，在Faster R-CNN中叫做锚，Anchors）

2. 简述一下YOLOv2的原理，v1和v2有什么区别？
    1. 增加了BN层：对于每个隐层神经元，避免梯度消失问题。YOLO网络在每一个卷积层后添加batch normalization，通过这一方法，mAP获得了2%的提升
    2. 使用更大图片为输入的分类器，然后finetune到检测网络：新的YOLO网络把分辨率直接提升到了448 * 448，这也意味之原有的网络模型必须进行某种调整以适应新的分辨率输入。作者首先对分类网络（自定义的darknet）进行了fine tune，分辨率改成448 * 448，在ImageNet数据集上训练10轮（10 epochs），训练后的网络就可以适应高分辨率的输入了。然后，作者对检测网络部分（也就是后半部分）也进行fine tune。这样通过提升输入的分辨率，mAP获得了4%的提升。
    3. 增加了Anchorbox的思想，增加网络的召回率：YOLO利用全连接层的数据完成边框的预测，导致丢失较多的空间信息，定位不准。作者在去掉了全连接层之后加入了anchor box（维度聚类之后），加入了anchor boxes后，可以预料到的结果是召回率上升，准确率下降。现在总共会预测13 * 13 * 9 = 1521个boxes，而之前的网络仅仅预测7 * 7 * 2 = 98个boxes

3. 非极大抑制是什么，有什么作用？
NMS算法主要解决的是一个目标被多次检测的问题，如图11中人脸检测，可以看到人脸被多次检测，但是其实我们希望最后仅仅输出其中一个最好的预测框，比如对于美女，只想要红色那个检测结果。那么可以采用NMS算法来实现这样的效果：首先从所有的检测框中找到置信度最大的那个框，然后挨个计算其与剩余框的IOU，如果其值大于一定阈值（重合度过高），那么就将该框剔除

## 3.循环卷积神经网络
1. LSTM为什么会导致梯度爆炸？要如何解决？
    1. 参数化的遗忘门控制流向下一个时间步的信息量
    
## 4.语义分割
1. 主要语义分割的算法有哪些，他们有什么区别？
2. deeplabv3的核心是什么？resnet101 ASPP
3. 感受野会受到什么因素的影响？怎么影响？
感受野是卷积层上某个像素对原图像的感受范围的大小， stride, 卷积神经网络的深度，空洞卷积层中dialation rate 设置都会影响。
其计算公式如下:

    本层的kernelsize*上一层的感受野-（上一层kernelsize-1）*（上一层的感受野-前面stride的连乘积）其中rn代表第n层的感受野，kn，sn代表第n层的kernel size，stride

    ![Pics/Untitled%205.png](../Pics/Untitled%205.png)

    [深度神经网络中的感受野(Receptive Field)](https://zhuanlan.zhihu.com/p/28492837)

## 5.Backbone
1. resnet中的恒等快捷连接在前向传播和反向传播都有什么作用？
    1. 在前向传播时可以将不同尺度的特征图进行相加，一起分析，提升对不同尺度的感受程度
    2. 在反向时，通过直连，使得梯度可以直接到达浅层神经网络，解决梯度消失的问题
    
## 6.卷积神经网络基础
1. Batch Normalization 在卷积神经网络中的作用是什么?

    通过将一个通道的所有特征图，进行归一化并再一次进行仿射变换。

    > 通过规范神经网络每一层输入的分布，限制因为分布变化带来的后层输出的不稳定，从而引起的链式效应。

    1. 在使用sigmoid/tanh激活函数时，限制神经元的输出范围，使得输出落在激活函数梯度较大的区域，避免梯度消失的情况，同样可以减少梯度爆炸的情况
    2. 在深层网络中限制浅层神经网络输出的变化范围，避免深层神经元对变化大的浅层神经元输出的不断适应导致的训练不稳定问题
    3. 将有不同量纲的变量统一到一个范围内，有利于学习
    4. 起到正则化的效果，因为限制输出的范围，从而将输出空间大大减小，
2. 1*1卷积的作用是什么？
1×1卷积核可以起到一个跨通道聚合的作用，所以进一步可以起到降维（或者升维）的作用，起到减少参数的目的。并且实现了不同channel上的特征融合
3. 两层较小的卷积核和一个较大的卷积核比较，各有什么缺点和优点？
两个3*3的卷积核在没有padding和stride为1的情况下，感受野和一层5*5的卷积核相同，但是参数量为9*2/25。
    1. 多层较小的卷积神经核在达到相同感受野的情况下，可以实现参数量的减少，因此减小显存的占用
    2. 多层的显著效果是使得网络层加深，那么加深的网络层在sigmoid/tanh层的作用下可能会存在梯度消失/爆炸的问题。
    3. 但也不排除使得因为网络加深核中间插入的非线性激活层使得网络的表达能力变强，从而能更好地拟合数据集
4. 不同激活函数有什么区别？
    1. sigmoid函数：其梯度值变化范围为（0-1/4）同时输入值特别大或者特别小的时候求出来的梯度特别小，因此在网络较深时，梯度叠加起来导致梯度消失

        $$f(z) = {1/(1+exp(-z))}; f'(z) = f(z)(1-f(z))$$

    2. tanh 函数：其导数范围为（0，1），网络较深导致梯度消失；输入相对sigmoid来说输出正负都有，更加平衡

        $$f(z) = tanh(z) = (e^{z} - e^{-z})/(e^{z}+e^{-z});  f'(z) = 1-(f(z))^2$$

    3. Relu函数：反向传播时不需要计算指数，相比说来计算量更小；因为不容易梯度消失，因此更多的神经元能有效激活；一定程度上促进稀疏性(神经元前向传播为负数时，该神经元就被杀死了，因此相当于变相的dropout)；但是在学习率过大是有可能导致一些神经元的不可逆死亡（学习率过大时，部分神经元一下更新到不合适的参数，因此，无论什么输入，输出都是负值）Leaky ReLU输入小于0的部分用很小的斜率，有助于缓解这个问题（即便输入是负数，也不会完全没有梯度更新）。

        $$f(z) = max(0,z); f'(z) = 1/0$$

5. 卷积层输出大小的计算

    一个H1*W1的特征图，加上上下左右加上padding，用长度为k的kernel，stride进行卷积，输出的卷积层大小为：(H1+2*padding-k)/stride + 1

6. dropout层为什么可以促进正则化？
dropout通过不断抛去一些神经元，限制了网络的表达能力，从而起到了正则化的效果。
7. 平方误差损失函数和交叉熵损失函数分别适用于什么场景？
    1. MSE更加适应输出为连续变化，并且最后一层不含softmax和sigmoid的神经网络，交叉熵更加适合分类问题
8. 梯度消失/爆炸的原因：
    1. 消失：由于sigmoid等函数容易饱和的特性，使得反向传播时可能会有多个小于一的值相乘，从而使得梯度消失
    2. 爆炸：卷积层参数w*激活函数的导数值大于1，连乘之后就变成一些很大的数值，这个可以通过梯度截断，损失函数权重正则化，
9. 损失降不下来怎么办？
    1. 检查是否采用了合适的损失函数，分类用交叉熵，回归用MSE
    2. 检查输入数据是否成功配对
    3. 检查学习率和学习策略是否正确
    4. 网络是否过于简单，没有合适的拟合能力
10. weight decay vs L2 正则项：
       weight decay 是在更新网络权重的时候，减去一个权重很小的一部分（比如说lambda1 = 0.0005），其直接作用在网络权重更新上，直接减少权重。L2正则项则是作用在损失函数上，使得网络权重在更新时也会减去权重本身的一部分，一般来说当正则项的惩罚系数设置成（lambda2 = lambda1/2），可以等效两种正则系数。

    ![Pics/Untitled%206.png](../Pics/Untitled%206.png)

                               weight decay vs L2 正则项

    ![Pics/Untitled%207.png](../Pics/Untitled%207.png)

                                       L1 正则项 vs L2 正则项



## 7.神经网络训练场景问题
1. 怎么判断过拟合，怎么处理？
       过拟合是由于模型太过复杂或者数据太少，导致的模型过度拟合训练样本的个性，从而导致用该模型预测其他样本结果时和真实值差异过大
    1. 通常以dropout层、添加噪声、或网络随机过程的某种形式进行
    2. 增加数据多样性，例如数据集增强等
    3. 提早结束
    4. batch normalization
2. 怎么解决图像语义分割中的样本不均衡问题：
    图像的语义分割问题就是像素级分类问题
    1. 使用不同类型的loss来均衡样本
    
        1. 交叉熵Loss：

    2. 使用注意力机制，当样本中出现某一类过多便不再给予关注

## 8.Python
1. 装饰器是什么，有什么作用？

    在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator），装饰器时一个返回函数的高阶函数。

           装饰器一般会使用python的@语法，在函数定义时进行在函数前一行执行@decorator，就相当于 令func = decorator(func)，即把func传入decorator函数，并使func等于decorator返回的函数（比如说是func2）。而func2内部可以在返回func调用的基础上再增加一些额外的功能，那么也就在不改变原来函数的基础上增加了额外的功能。

        import functools
        
        def log(func):
                @functools.wraps(func)   # 保留now在decorator调用之后的函数属性
            def wrapper(*args, kw):
                print('call %s():' % func.__name__)
                return func(*args, kw)
            return wrapper
        
        @log            ##等效于 now = log(now)
        def now():
            print('2015-3-25')

2. 迭代器：代表了一个惰性的有序序列，提前并不知道序列的长度

    可以被for循环作用的成为可迭代对象iterable：比如集合数据类型：list，tuple，dict，set，str等；以及生成器和生成函数

    可以被next调用并不断生成下一个值的对象叫做iterator，例如生成器和被iter() 函数转换的集合数据类型

3. 生成器：
Python中，这种一边循环一边计算的机制，称为生成器：generator。

    创建一个生成器只需要将list中的[] 改为()，并使用next()/for循环函数进行调用；或者也可以通过函数内部+yield 生成生成器，并用for循环获取生成值
