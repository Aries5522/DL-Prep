{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 面试题\n",
    "将见过的面试题和自己想到查到的回答\n",
    "\n",
    "* [1. 训练加速](#1.训练加速)\n",
    "    * 数据并行\n",
    "    * 数据并行(nn.distributed) \\* [todo]\n",
    "    * 模型并行  \n",
    "    * pytorch的dataparallel\n",
    "\n",
    "* [2. 目标检测](#2.目标检测)\n",
    "    * 1.算法有哪些？他们的对比？\n",
    "        * RCNN：\n",
    "        * fast RCNN\n",
    "        * faster RCNN\n",
    "        * YOLO\n",
    "        * SSD\n",
    "    * 2.简述一下YOLOv2的原理，v1和v2有什么区别？\n",
    "    * 3.非极大抑制是什么，有什么作用？\n",
    "    * 4.如何实现mOU 和非极大抑制？即手推计算过程。 \\* [todo]\n",
    "    * 5.nms的发展（greedy-nms，soft-nms，fast-nms，matrix-nms） \\* [todo]\n",
    "    * 6.YOLOv2为什么将输入尺寸从448降到416 \\* [todo]\n",
    "    * 7.YOLOv2对于anchor的使用与faster-rcnn有何不同  \\* [todo]\n",
    "    * 8.YOLOv2,v3一个anchor可以对应几个GT？SSD呢？RCNN系列呢？ \\* [todo]\n",
    "    * 9.YOLOv3对于v2做了怎样的改进？ \\* [todo]\n",
    "    * 10.YOLOv2与v3筛选正负样本的方式类似，具体是怎样进行的？这种操作解决了什么问题？ \\* [todo]\n",
    "    * 11.YOLOv3的多尺度输出结构与FPN有何不同？ \\* [todo]\n",
    "    * 12.YOLOv2,v3的anchor聚类如何做？指标是什么？ \\* [todo]\n",
    "    * 13.FPN的多尺度输出结构与SSD的多尺度输出结构哪个效果更好 \\* [todo]\n",
    "    * 14.faster-rcnn在撒anchor的时候，是如何把特征图坐标映射到图像上的？ \\* [todo]\n",
    "    * 15.faster-rcnn的OHEM与ssd的OHEM有何不同 \\* [todo]\n",
    "    * 16.roi pooling与roi align的具体操作 \\* [todo]\n",
    "    * 17.retinanet解决了以往one-stage检测器的什么问题 \\* [todo]\n",
    "    * 18.Focal loss一定有效吗？为什么？试举出一个例子 \\* [todo]\n",
    "    * 19.介绍cascade-RCNN和DCN模块。Cascade-rcnn解决了什么问题？cascade-RCNN一般选用几个阶段？ \\* [todo]\n",
    "    * 20.anchor-free的方式大概分为哪两种？各有什么特点？ \\* [todo]\n",
    "    * 21.coco的mAP的计算公式 \\* [todo]\n",
    "    \n",
    "* [3. 循环卷积神经网络](#3.循环卷积神经网络)\n",
    "    * 1.LSTM为什么会导致梯度爆炸？要如何解决？\n",
    "\n",
    "* [4. 语义分割](#4.语义分割)\n",
    "    * 1.主要语义分割的算法有哪些，他们有什么区别？\n",
    "    * 2.deeplabv3的核心是什么？\n",
    "    * 3.感受野会受到什么因素的影响？怎么影响？\n",
    "    * 4.介绍空洞卷积以及DeepLabv3中的ASPP模块 \\* [todo]\n",
    "    * 5.双线性插值，转置卷积和反卷积的区别与联系 \\* [todo]\n",
    "    * 6.介绍语义分割、实例分割和全景分割 \\* [todo]\n",
    "    * 7.后处理方法：CRF \\* [todo]\n",
    "\n",
    "* [5. Backbone](#5.Backbone)\n",
    "    * 1.resnet中的恒等快捷连接在前向传播和反向传播都有什么作用？\n",
    "    * 2.ResNet和ResNeXt的区别 \\* [todo]\n",
    "\n",
    "* [6. 卷积神经网络基础](#6.卷积神经网络基础)\n",
    "    * 1.Batch Normalization 在卷积神经网络中的作用是什么?\n",
    "    * 2.1*1卷积的作用是什么？\n",
    "    * 3.两层较小的卷积核和一个较大的卷积核比较，各有什么缺点和优点？\n",
    "    * 4.不同激活函数有什么区别？\n",
    "    * 5.卷积层输出大小的计算?\n",
    "    * 6.dropout层为什么可以促进正则化？pytorch中dropout在训练与测试时如何使用？\n",
    "    * 7.平方误差损失函数和交叉熵损失函数分别适用于什么场景？\n",
    "    * 8.梯度消失/爆炸的原因?\n",
    "    * 9.损失降不下来怎么办？\n",
    "    * 10.weight decay vs L2 正则项\n",
    "    * 11.avarage-pooling与max-pooling的区别与联系？它们的梯度反传如何进行？\n",
    "    * 12.各种normalization层了解多少？(包括SyncBN)\n",
    "    * 13.为什么学习率的设置要与batchsize成线型关系\n",
    "    * 14.ReLU有哪些改进的方式\n",
    "    * 15.神经网络中参数中的偏置bias有什么作用\n",
    "    * 16.caffe的im2col是怎么操作的？ \\* [todo]\n",
    "\n",
    "* [7. 神经网络训练场景问题](#7.神经网络训练场景问题)\n",
    "    * 1.怎么判断过拟合，怎么处理？\n",
    "    * 2.怎么解决图像语义分割中的样本不均衡问题?\n",
    "\n",
    "* [8. Python](#8.Python)\n",
    "    * 1.装饰器是什么，有什么作用？\n",
    "    * 2.迭代器\n",
    "    * 3.生成器\n",
    "    * 4.深拷贝与浅拷贝的区别 \\* [todo]\n",
    "    * 5.Python中is和==的区别\n",
    "    * 6.解释with语句\n",
    "    * 7.什么是面向对象？面向过程和面向对象的区别？\n",
    "    \n",
    "\n",
    "* [9. 机器学习](#9.机器学习)\n",
    "    * 1.讲讲逻辑回归和支持向量机 \\* [todo]\n",
    "    * 2.手写逻辑回归的损失函数 \\* [todo]\n",
    "    \n",
    "* [10. 传统图像处理](#10.传统图像处理)\n",
    "\n",
    "\n",
    "\n",
    "## 1.训练加速\n",
    "1. 使用多块GPU时要如何设置？\n",
    "\n",
    "数据并行：\n",
    "1. 将CUDA_VISIBLE_DEVICES设置成想要运行的几块卡\n",
    "2. 使用nn.DataParallel函数将模型包起来，并传入指定的GPU\n",
    "3. 将模型和数据都.cuda() 传入GPU\n",
    "\n",
    "数据并行（ nn.distributed ）--需要有batchsize>1才可以\n",
    "**todo**: nn.distribute\n",
    "\n",
    "模型并行：\n",
    "\n",
    "1. 将模型通过在模型定义的部分拆分到几块不同的显卡上\n",
    "2. 在forward部分将数据传到对应的显卡并前传  \n",
    "\n",
    "pytorch的dataparallel：  \n",
    "&ensp;&ensp;&ensp;&ensp;流程图如下：  \n",
    "![avatar](./Pics/dp_0.png)\n",
    "&ensp;&ensp;&ensp;&ensp;总的来说就是：复制module-分发数据-forward-计算loss-backward-汇总梯度-更新参数-复制module-...一直循环。  \n",
    "&ensp;&ensp;&ensp;&ensp;前传以及反传过程如下图：  \n",
    "![avatar](./Pics/dp_1.jpg)  \n",
    "&ensp;&ensp;&ensp;&ensp;**注意某个参数梯度是先在各卡上分别计算出来再相加**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2.目标检测\n",
    "1. 算法有哪些？他们的对比？\n",
    "主要算法有 rcnn（region-convnet）系列，SSD，Retina net，yolov1v2v3等，其中rcnn网络为两阶段网络，即将目标检测中的定位和识别任务分为两个步骤进行解决，缺点在于速度较慢，优点在于准确度较高\n",
    "    1. RCNN：\n",
    "\n",
    "        ![Pics/Untitled.png](Pics/Untitled.png)\n",
    "\n",
    "        首先使用selective search（评估图像相邻部分的相似度并将相似度高的部分合并并打分，选出评分较高的2000个子图）在原始图片中选择出子图；\n",
    "\n",
    "        随后将提取出的子图进行warp，从而采用一个统一的大小，同样大小的子图输入特征提取网络（卷积-relu-池化-全连接）进行特征提取；\n",
    "\n",
    "        根据每个子图提取的特征进行分类，保留某一类打分较高的区块，作为物体的最终定位区块\n",
    "\n",
    "        它较慢的原因主要在于一张图片要提取2000个子图，每个子图都要做特征提取\n",
    "\n",
    "    2. fast RCNN：\n",
    "        -\n",
    "\n",
    "        ![https://img.mukewang.com/5b2bbbd6000129a213380536.jpg](https://img.mukewang.com/5b2bbbd6000129a213380536.jpg)\n",
    "\n",
    "        - 引入ROI-pooling结构，在将图片warp的部分改为使用ROI pooling，因为特征提取网络中采用了全连接神经网络，因此传入全连接层的特征图大小必须一致，之前采用了对原始图片进行warp，这样容易使得图片产生形变和信息丢失，而且这个操作较费事，现在采用ROI pooling，即根据变换后图片的尺寸例如M*N，将特征图分为M*N个方格，并取出其中的最大值（最显著的特征），加快了操作\n",
    "        - 提出多任务损失的思想，将分类损失和边框定位损失结合在一起统一训练\n",
    "        - 将整图只通过一次CNN网络就提取所有ROI的特征。因为2000个子图在原图上有很多重叠，因此每个子图都通过一个特征提取网络是费时费力的，因此，通过区域投影的方式，将整图通过特征提取网络，再利用区域投影将整图的特征取出ROI的那一部分，即可通过一次特征提取网络，得到所有的ROI的特征\n",
    "    3. faster RCNN：\n",
    "\n",
    "        ![Pics/Untitled%201.png](Pics/Untitled%201.png)\n",
    "\n",
    "        这个部分的改进是将原本的ROI提取方法—selective search 改为了Region Proposal Network，这样大大增加了提取目标框的速度。RPN网络通过在原始卷积层上提取的特征经过进一步3*3卷积增加感受野，得到了提取ROI和调整ROI边界两个支路，\n",
    "\n",
    "        在提取ROI支路上，基于之前在CONV5的特征图上每一个点生成的k个anchor，随后通过1*1卷积获得W*H*18的输出结果，这个结果代表每个点9个anchor，前景和背景的两个结果，随后通过reshape和softmax得到概率，区分目标是前景还是后景（这一步的判断是为了去除大量无用的背景anchor）；\n",
    "\n",
    "        另一条通过1*1卷积reshape到36层的特征图是对应于bbox相对于原始anchor的偏移量，由于通过四个线性变换参数，anchor就可以变换中心点位置和长宽，从而变换到接近到GT的bbox坐标，因此通过原始特征图变换就可以得到这四个参数，由于每个点有9个anchor，同时每个anchor需要四个参数调整位置，因此这一层的输出有36层；\n",
    "\n",
    "        回到图，VGG输出50*38*512的特征，对应设置50*38*k个anchors，而RPN输出：\n",
    "\n",
    "        1. 大小为50*38*2k 的positive/negative softmax分类特征矩阵\n",
    "        2. 大小为50*38*4k的regression坐标回归特征矩阵\n",
    "\n",
    "        最后proposal层综合主要的前景anchors和对应的偏移量结合NMS和一些筛选方法获取proposal；\n",
    "\n",
    "        其实RPN最终就是在原图尺度上，设置了密密麻麻的候选Anchor。然后用cnn去判断哪些Anchor是里面有目标的positive anchor，哪些是没目标的negative anchor。所以，仅仅是个二分类而已！\n",
    "\n",
    "        特征图生成anchor，anchor长宽和中心点变换，anchor NMS筛选\n",
    "\n",
    "        随后，这些proposals 通过ROI pooling层用于后续的ROI大小统一，并用于分类操作，分类后的ROI还需要进一步调整bbox的大小。\n",
    "\n",
    "    4. YOLO\n",
    "\n",
    "        ![Pics/Untitled%202.png](Pics/Untitled%202.png)\n",
    "\n",
    "        在网络结构上，YOLO分为三个部分，第一个部分是特征提取网络，用于提取有用的可泛化的特征，第二部分为目标检测网络，在目标检测网络之后，就获得了7*7*30的输出结果，这个部分相当于将原图分为了7*7的网格，每个网格预测两个长宽不同的anchor的位置和长宽，以及这两个anchor的置信分数（是否有目标*和真实bbox的IOU）以及这个格子内的物体属于哪一个类别。\n",
    "\n",
    "        将原图划分成S*S大小的格子，每个格子用于预测中心点落在格子内的目标。\n",
    "                每个各自预测B个边界框和他们对应的置信度（置信度是边界框中有目标的概率*这个边界框的准确度，用IOU来衡量）。\n",
    "                而为了表示边界框，需要使用（x,y,w,h）表示，结合上置信度，则每个边界框预测（x,y,w,h,c）。\n",
    "                除此之外，对于每个格子会预测一组条件类别概率C，因此每个格子会产生（B*5+C）大小的向量，总共就是（S*S,B*5+C）\n",
    "\n",
    "        ![Pics/Untitled%203.png](Pics/Untitled%203.png)\n",
    "\n",
    "        损失函数中，使用了MSEloss，对于不同类别的误差采取了系数进行调控。\n",
    "\n",
    "        yolo算法开创了one-stage检测的先河，它将物体分类和物体检测网络合二为一，都在全连接层完成。故它大大降低了目标检测的耗时，提高了实时性。但它的缺点也十分明显\n",
    "\n",
    "        1. 每个网格只对应两个bounding box，当物体的长宽比不常见（也就是训练数据集覆盖不到时），效果很差。\n",
    "        2. 原始图片只划分为7x7的网格，当两个物体靠的很近时，效果很差\n",
    "        3. 最终每个网格只对应一个类别，容易出现漏检（物体没有被识别到）。\n",
    "        4. 对于图片中比较小的物体，效果很差。这其实是所有目标检测算法的通病，SSD对它有些优化，我们后面再看。\n",
    "    5. SSD Single Shot MultiBox Detector\n",
    "\n",
    "        ![Pics/Untitled%204.png](Pics/Untitled%204.png)\n",
    "\n",
    "        相比Yolo，SSD采用CNN来直接进行检测，而不是像Yolo那样在全连接层之后做检测。SSD提取了不同尺度的特征图来做检测，大尺度特征图（较靠前的特征图）可以用来检测小物体，而小尺度特征图（较靠后的特征图）用来检测大物体；\n",
    "\n",
    "        SSD采用了不同尺度和长宽比的先验框（Prior boxes, Default boxes，在Faster R-CNN中叫做锚，Anchors）\n",
    "\n",
    "2. 简述一下YOLOv2的原理，v1和v2有什么区别？\n",
    "    1. 增加了BN层：对于每个隐层神经元，避免梯度消失问题。YOLO网络在每一个卷积层后添加batch normalization，通过这一方法，mAP获得了2%的提升\n",
    "    2. 使用更大图片为输入的分类器，然后finetune到检测网络：新的YOLO网络把分辨率直接提升到了448 * 448，这也意味之原有的网络模型必须进行某种调整以适应新的分辨率输入。作者首先对分类网络（自定义的darknet）进行了fine tune，分辨率改成448 * 448，在ImageNet数据集上训练10轮（10 epochs），训练后的网络就可以适应高分辨率的输入了。然后，作者对检测网络部分（也就是后半部分）也进行fine tune。这样通过提升输入的分辨率，mAP获得了4%的提升。\n",
    "    3. 增加了Anchorbox的思想，增加网络的召回率：YOLO利用全连接层的数据完成边框的预测，导致丢失较多的空间信息，定位不准。作者在去掉了全连接层之后加入了anchor box（维度聚类之后），加入了anchor boxes后，可以预料到的结果是召回率上升，准确率下降。现在总共会预测13 * 13 * 9 = 1521个boxes，而之前的网络仅仅预测7 * 7 * 2 = 98个boxes\n",
    "\n",
    "3. 非极大抑制是什么，有什么作用？\n",
    "    NMS算法主要解决的是一个目标被多次检测的问题，如图11中人脸检测，可以看到人脸被多次检测，但是其实我们希望最后仅仅输出其中一个最好的预测框，比如对于美女，只想要红色那个检测结果。那么可以采用NMS算法来实现这样的效果：首先从所有的检测框中找到置信度最大的那个框，然后挨个计算其与剩余框的IOU，如果其值大于一定阈值（重合度过高），那么就将该框剔除\n",
    "\n",
    "19. 介绍cascade-RCNN和DCN模块。Cascade-rcnn解决了什么问题？cascade-RCNN一般选用几个阶段？\n",
    "    介绍cascade-RCNN就会涉及到IoU。Faster-RCNN通过RoI与标签的IoU值来判断这个RoI是正样本还是负样本。这个IoU阈值是一个超参数，对于检测的精度有着较大的影响。因此IoU值的选择很重要。\n",
    "    2018年CVPR上的cascade-RCNN算法通过级联多个检测器来不断优化结果，每一个检测器的边框输出都作为下一个检测器的输入，每个检测器都基于不同的IoU阈值来界定正负样本，而且检测器的IoU阈值是逐渐提升的。IoU阈值越高，检测器的定位更加准确，但是会导致正负样本更加不均衡，容易过拟合；阈值越低，正样本更多，有利于训练，但是误检也会增多。因此，这种级联方式的检测器可以逐步过滤掉一些误检框，同时能够逐步提升边框的定位精度。\n",
    "    总而言之，cascade-RCNN算法深入探讨了IoU阈值对检测器性能的影响，能够在不增加任何trick的前提下，在多个数据集上都有了明显的精度提升，是一个性能优越的高精度目标检测器。\n",
    "    ![avatar](./Pics/cascade-RCNN.png)\n",
    "    3个阶段的时候准确率已经很高了，第四阶段已经没有增益了。\n",
    "\n",
    "## 3.循环卷积神经网络\n",
    "1. LSTM为什么会导致梯度爆炸？要如何解决？\n",
    "    1. 参数化的遗忘门控制流向下一个时间步的信息量\n",
    "\n",
    "## 4.语义分割\n",
    "1. 主要语义分割的算法有哪些，他们有什么区别？\n",
    "2. deeplabv3的核心是什么？resnet101 ASPP\n",
    "3. 感受野会受到什么因素的影响？怎么影响？\n",
    "感受野是卷积层上某个像素对原图像的感受范围的大小， stride, 卷积神经网络的深度，空洞卷积层中dialation rate 设置都会影响。\n",
    "其计算公式如下:\n",
    "\n",
    "    本层的kernelsize*上一层的感受野-（上一层kernelsize-1）*（上一层的感受野-前面stride的连乘积）其中rn代表第n层的感受野，kn，sn代表第n层的kernel size，stride\n",
    "\n",
    "    ![Pics/Untitled%205.png](Pics/Untitled%205.png)\n",
    "\n",
    "    [深度神经网络中的感受野(Receptive Field)](https://zhuanlan.zhihu.com/p/28492837)\n",
    "\n",
    "## 5.Backbone\n",
    "1. resnet中的恒等快捷连接在前向传播和反向传播都有什么作用？\n",
    "    1. 在前向传播时可以将不同尺度的特征图进行相加，一起分析，提升对不同尺度的感受程度\n",
    "    2. 在反向时，通过直连，使得梯度可以直接到达浅层神经网络，解决梯度消失的问题\n",
    "\n",
    "## 6.卷积神经网络基础\n",
    "1. Batch Normalization 在卷积神经网络中的作用是什么?\n",
    "\n",
    "    通过将一个通道的所有特征图，进行归一化并再一次进行仿射变换。\n",
    "\n",
    "    > 通过规范神经网络每一层输入的分布，限制因为分布变化带来的后层输出的不稳定，从而引起的链式效应。\n",
    "\n",
    "    1. 在使用sigmoid/tanh激活函数时，限制神经元的输出范围，使得输出落在激活函数梯度较大的区域，避免梯度消失的情况，同样可以减少梯度爆炸的情况\n",
    "    2. 在深层网络中限制浅层神经网络输出的变化范围，避免深层神经元对变化大的浅层神经元输出的不断适应导致的训练不稳定问题\n",
    "    3. 将有不同量纲的变量统一到一个范围内，有利于学习\n",
    "    4. 起到正则化的效果，因为限制输出的范围，从而将输出空间大大减小，\n",
    "2. 1*1卷积的作用是什么？\n",
    "1×1卷积核可以起到一个跨通道聚合的作用，所以进一步可以起到降维（或者升维）的作用，起到减少参数的目的。并且实现了不同channel上的特征融合\n",
    "3. 两层较小的卷积核和一个较大的卷积核比较，各有什么缺点和优点？\n",
    "两个3*3的卷积核在没有padding和stride为1的情况下，感受野和一层5*5的卷积核相同，但是参数量为9*2/25。\n",
    "    1. 多层较小的卷积神经核在达到相同感受野的情况下，可以实现参数量的减少，因此减小显存的占用\n",
    "    2. 多层的显著效果是使得网络层加深，那么加深的网络层在sigmoid/tanh层的作用下可能会存在梯度消失/爆炸的问题。\n",
    "    3. 但也不排除使得因为网络加深核中间插入的非线性激活层使得网络的表达能力变强，从而能更好地拟合数据集\n",
    "4. 不同激活函数有什么区别？\n",
    "    1. sigmoid函数：其梯度值变化范围为（0-1/4）同时输入值特别大或者特别小的时候求出来的梯度特别小，因此在网络较深时，梯度叠加起来导致梯度消失\n",
    "\n",
    "        $$f(z) = {1/(1+exp(-z))}; f'(z) = f(z)(1-f(z))$$\n",
    "\n",
    "    2. tanh 函数：其导数范围为（0，1），网络较深导致梯度消失；输入相对sigmoid来说输出正负都有，更加平衡\n",
    "\n",
    "        $$f(z) = tanh(z) = (e^{z} - e^{-z})/(e^{z}+e^{-z});  f'(z) = 1-(f(z))^2$$\n",
    "\n",
    "    3. Relu函数：反向传播时不需要计算指数，相比说来计算量更小；因为不容易梯度消失，因此更多的神经元能有效激活；一定程度上促进稀疏性(神经元前向传播为负数时，该神经元就被杀死了，因此相当于变相的dropout)；但是在学习率过大是有可能导致一些神经元的不可逆死亡（学习率过大时，部分神经元一下更新到不合适的参数，因此，无论什么输入，输出都是负值）Leaky ReLU输入小于0的部分用很小的斜率，有助于缓解这个问题（即便输入是负数，也不会完全没有梯度更新）。\n",
    "\n",
    "        $$f(z) = max(0,z); f'(z) = 1/0$$\n",
    "\n",
    "5. 卷积层输出大小的计算\n",
    "\n",
    "    一个H1*W1的特征图，加上上下左右加上padding，用长度为k的kernel，stride进行卷积，输出的卷积层大小为：(H1+2*padding-k)/stride + 1\n",
    "\n",
    "6. dropout层为什么可以促进正则化？pytorch中dropout在训练与测试时如何使用？\n",
    "dropout通过不断抛去一些神经元，限制了网络的表达能力，从而起到了正则化的效果。pytorch中，训练时网络的所有单元以概率p丢弃，剩余的单元的输出乘以（1/1-p），测试的时候直接使用所有单元。\n",
    "7. 平方误差损失函数和交叉熵损失函数分别适用于什么场景？\n",
    "    1. MSE更加适应输出为连续变化，并且最后一层不含softmax和sigmoid的神经网络，交叉熵更加适合分类问题\n",
    "8. 梯度消失/爆炸的原因：\n",
    "    1. 消失：由于sigmoid等函数容易饱和的特性，使得反向传播时可能会有多个小于一的值相乘，从而使得梯度消失\n",
    "    2. 爆炸：卷积层参数w*激活函数的导数值大于1，连乘之后就变成一些很大的数值，这个可以通过梯度截断，损失函数权重正则化，\n",
    "9. 损失降不下来怎么办？\n",
    "    1. 检查是否采用了合适的损失函数，分类用交叉熵，回归用MSE\n",
    "    2. 检查输入数据是否成功配对\n",
    "    3. 检查学习率和学习策略是否正确\n",
    "    4. 网络是否过于简单，没有合适的拟合能力\n",
    "10. weight decay vs L2 正则项：\n",
    "       weight decay 是在更新网络权重的时候，减去一个权重很小的一部分（比如说lambda1 = 0.0005），其直接作用在网络权重更新上，直接减少权重。L2正则项则是作用在损失函数上，使得网络权重在更新时也会减去权重本身的一部分，一般来说当正则项的惩罚系数设置成（lambda2 = lambda1/2），可以等效两种正则系数。\n",
    "\n",
    "    ![Pics/Untitled%206.png](Pics/Untitled%206.png)\n",
    "\n",
    "                               weight decay vs L2 正则项\n",
    "\n",
    "    ![Pics/Untitled%207.png](Pics/Untitled%207.png)\n",
    "\n",
    "                                       L1 正则项 vs L2 正则项\n",
    "11. avarage-pooling与max-pooling的区别与联系？它们的梯度反传如何进行？  \n",
    "    pooling的结果是使得特征减少，参数减少，但pooling的目的并不仅在于此。pooling目的是为了保持某种不变性（旋转、平移、伸缩等），同时降低网络对于特征图细节的敏感性。  \n",
    "    根据相关理论，特征提取的误差主要来自两个方面：\n",
    "    * 邻域大小受限造成的估计值方差增大；\n",
    "    * 卷积层参数误差造成估计均值的偏移。  \n",
    "\n",
    "    mean-pooling能减小第一种误差（邻域大小受限造成的估计值方差增大），更多的保留图像的背景信息，  \n",
    "    max-pooling能减小第二种误差（卷积层参数误差造成估计均值的偏移），更多的保留纹理信息。  \n",
    "    &ensp;&ensp;&ensp;&ensp;avg-pooling实际上是一个线性操作，而max-pooling是一个非线性的操作，因此网络中间层使用max-pooling也是考虑到了其非线性的特点，提高网络的复杂度。pooling会有信息损失，在segmentation等有encoder-decoder功能的网络里会降低性能。但是反过来说，池化也有防止过拟合的作用  \n",
    "\n",
    "    两种pooling的梯度反传\n",
    "    ![avatar](./Pics/mean_pooling.jpeg)\n",
    "    ![avatar](./Pics/max_pooling.jpeg)\n",
    "12. 各种normalization层了解多少？  \n",
    "    ![avatar](./Pics/n.png)  \n",
    "    * BN：  \n",
    "        1.BN的计算就是把每个通道的NHW单独拿出来归一化处理   \n",
    "\n",
    "        2.针对每个channel我们都有一组γ,β，所以可学习的参数为2*C  \n",
    "\n",
    "        3.当batch size越小，BN的表现效果也越不好，因为计算过程中所得到的均值和方差不能代表全局  \n",
    "\n",
    "    * LN：  \n",
    "        1.LN的计算就是把每个CHW单独拿出来归一化处理，不受batchsize的影响\n",
    "\n",
    "        2.常用在RNN网络，但如果输入的特征区别很大，那么就不建议使用它做归一化处理  \n",
    "\n",
    "    * IN：  \n",
    "\n",
    "        1.IN的计算就是把每个HW单独拿出来归一化处理，不受channel和batchsize 的影响  \n",
    "\n",
    "        2.常用在风格化迁移，但如果特征图可以用到通道之间的相关性，那么就不建议使用它做归一化处理  \n",
    "\n",
    "    * GN：  \n",
    "\n",
    "        1.GN的计算就是把先把通道C分成G组，然后把每个gHW单独拿出来归一化处理，最后把G组归一化之后的数据合并成CHW\n",
    "\n",
    "        2.GN介于LN和IN之间，当然可以说LN和IN就是GN的特列，比如G的大小为1或者为C  \n",
    "\n",
    "        **补充：关于GN，详细可见 https://www.cnblogs.com/jins-note/p/11342565.html**  \n",
    "\n",
    "        **GN解决了BN的两个问题：1.依赖于batchsize，bs太小时，性能明显下降 2.测试数据与训练数据有差时，会造成mean与var的不一致**  \n",
    "\n",
    "        **GN为什么work：每一层有很多的卷积核，这些核学习到的特征并不完全是独立的，某些特征具有相同的分布，因此可以被group**\n",
    "\n",
    "    * Switchable Normalization：\n",
    "\n",
    "        1.将 BN、LN、IN 结合，赋予权重，让网络自己去学习归一化层应该使用什么方法\n",
    "\n",
    "        2.集万千宠爱于一身，但训练复杂  \n",
    "\n",
    "    * **SyncBN**：  \n",
    "\n",
    "        SyncBN具体可见链接https://zhuanlan.zhihu.com/p/69940683 与 https://www.cnblogs.com/makefile/p/batch-norm.html?utm_source=debugrun&utm_medium=referral **主要解决了在数据并行时,BN的mean和var分开统计的问题**\n",
    "        \n",
    "13. 为什么学习率的设置要与batchsize成线型关系?  \n",
    "    具体可见 https://www.zhihu.com/question/64134994/answer/216895968 。总的来说有以下三点：  \n",
    "    * 大batch的数据梯度方差小，噪声小，可以用大lr提高收敛速度。从方差的角度上看，更大的batch意味着一个mini-batch中样本的方差更小，也同时意味着一个mini-batch带来的梯度方差也更小，梯度更加可信，噪声给模型带来的影响也会相应减少，在可信的梯度下，我们可以使用更大的learning rate来更新参数，提高收敛速度是可行的。  \n",
    "    * 适当的增大learning rate还可以有效避免模型走到一个比较差的local minima  \n",
    "    * 决定收敛快慢的有三个因素：梯度好坏，步幅（lr），步数（iter）。在epoch不变的情况下，大的batch造成iter要小，就是说步数要小，这个时候增大步幅才可以避免因为步数少而不收敛的情况。公式上的解释可以参考链接  \n",
    "14. ReLU有哪些改进的方式  \n",
    "    详见 https://www.cnblogs.com/XDU-Lakers/p/10557496.html 与 https://blog.csdn.net/weixin_41417982/article/details/81437088?utm_source=blogxgwz9  \n",
    "    主要有以下的改进方式：\n",
    "    ![avatar](./Pics/relu.png)  \n",
    "    其中LReLU解决了Dead relu的问题。因为Leaky ReLU保留了x小于0时的梯度，在x小于0时，不会出现神经元死亡的问题。对于Leaky ReLU给出了一个很小的负数梯度值α，这个值是很小的常数。比如：0.01。这样即修正了数据分布，又保留了一些负轴的值，使得负轴信息不会全部丢失。但是这个α通常是通过先验知识人工赋值的。  \n",
    "    PRElu的α是加入训练得到的，Rrelu的α在训练的时候是从一个高斯分布中随机取出来的，然后在测试的过程中，把训练过程中所有的α取个平均值。  \n",
    "15. 神经网络中参数中的偏置bias有什么作用  \n",
    "    bias平移拟合曲线，可以更好地拟合数据。比如对于sigmoid，若想在x=2的时候使得输出等于0，那么无论怎么改变w都很难做到，只能做平移取得。  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 7.神经网络训练场景问题\n",
    "1. 怎么判断过拟合，怎么处理？\n",
    "       过拟合是由于模型太过复杂或者数据太少，导致的模型过度拟合训练样本的个性，从而导致用该模型预测其他样本结果时和真实值差异过大\n",
    "    1. 通常以dropout层、添加噪声、或网络随机过程的某种形式进行\n",
    "    2. 增加数据多样性，例如数据集增强等\n",
    "    3. 提早结束\n",
    "    4. batch normalization\n",
    "2. 怎么解决图像语义分割中的样本不均衡问题：\n",
    "    图像的语义分割问题就是像素级分类问题\n",
    "    1. 使用不同类型的loss来均衡样本\n",
    "\n",
    "        1. 交叉熵Loss：\n",
    "\n",
    "    2. 使用注意力机制，当样本中出现某一类过多便不再给予关注\n",
    "\n",
    "## 8.Python\n",
    "1. 装饰器是什么，有什么作用？\n",
    "\n",
    "    在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator），装饰器时一个返回函数的高阶函数。\n",
    "\n",
    "           装饰器一般会使用python的@语法，在函数定义时进行在函数前一行执行@decorator，就相当于 令func = decorator(func)，即把func传入decorator函数，并使func等于decorator返回的函数（比如说是func2）。而func2内部可以在返回func调用的基础上再增加一些额外的功能，那么也就在不改变原来函数的基础上增加了额外的功能。\n",
    "\n",
    "        import functools\n",
    "\n",
    "        def log(func):\n",
    "                @functools.wraps(func)   # 保留now在decorator调用之后的函数属性\n",
    "            def wrapper(*args, kw):\n",
    "                print('call %s():' % func.__name__)\n",
    "                return func(*args, kw)\n",
    "            return wrapper\n",
    "\n",
    "        @log            ##等效于 now = log(now)\n",
    "        def now():\n",
    "            print('2015-3-25')\n",
    "\n",
    "2. 迭代器：代表了一个惰性的有序序列，提前并不知道序列的长度\n",
    "\n",
    "    可以被for循环作用的成为可迭代对象iterable：比如集合数据类型：list，tuple，dict，set，str等；以及生成器和生成函数\n",
    "\n",
    "    可以被next调用并不断生成下一个值的对象叫做iterator，例如生成器和被iter() 函数转换的集合数据类型\n",
    "\n",
    "3. 生成器：\n",
    "Python中，这种一边循环一边计算的机制，称为生成器：generator。\n",
    "\n",
    "    创建一个生成器只需要将list中的[] 改为()，并使用next()/for循环函数进行调用；或者也可以通过函数内部+yield 生成生成器，并用for循环获取生成值\n",
    "  \n",
    "4. 深拷贝与浅拷贝的区别\n",
    "\n",
    "5. Python中is和==的区别\n",
    "    is是用来判断两个变量引用的对象是否为同一个；==用于判断引用对象的值是否相等。（可以通过id()函数查看引用对象的地址）\n",
    "\n",
    "6. 解释with语句\n",
    "    关键字with在不再需要访问文件后将其关闭。在with语句中，我们只调用open()，但不调用close();你也可以调用open()和close()来打开和关闭文件，但这样做时，如果程序存在bug，导致close()语句未执行，文件将不会关闭。这看似微不足道，但未妥善地关闭文件可能会导致数据丢失或受损。如果在程序中过早地调用close()，你会发现需要使用文件时它已关闭(无法访问)，这会导致更多的错误。并非在任何情况下都能轻松确定关闭文件的恰当时机，但通过使用with结构的语句，可让Python去确定:你只管打开文件，并在需要时使用它，Python自会在合适的时候自动将其关闭。\n",
    "\n",
    "7. 什么是面向对象？面向过程和面向对象的区别？\n",
    "    面向对象和面向过程都只是解决问题的一种思路而已。\n",
    "    面向过程：将数据与函数按照执行的逻辑顺序组织在一起，数据与函数是分开的，由于从上到下写代码，代码会很长；\n",
    "    面向对象：将数据与函数绑定到一起，进行封装，这样能够快速地开发程序，减少了重复代码的重写过程。\n",
    "    面向对象的三大特性：封装，继承，多态。\n",
    "    简而言之，面向过程就是所有步骤、过程都需要亲自去实现，而面向对象则是创建、调用一个拥有这些方法的对象，并令该对象执行。\n",
    "    面向对象也是基于面向过程的。\n",
    "\n",
    "    \n",
    "## 9.机器学习\n",
    "\n",
    "## 10.传统图像处理\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
