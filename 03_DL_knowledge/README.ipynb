{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 深度学习知识总结\n",
    "先从伯禹的学习资料入手，边学习，边 [整理记录](https://github.com/shiyutang/Hands-on-deep-learning) +《\n",
    "[神经网络和深度学习](https://nndl.github.io/nndl-book.pdf)\n",
    "》补充；\n",
    "累了可以听听 [MIT 的6.S191](https://www.youtube.com/watch?v=JN6H4rQvwgY) refresh一下\n",
    "\n",
    "根据下列框架进行结构性的知识总结。\n",
    "\n",
    "1.浅层神经网络及模型基础\n",
    "\n",
    "* [1.1 线性回归](#线性回归)\n",
    "    * 定义\n",
    "    * 实施步骤\n",
    "    * 要点\n",
    "    * 主要函数\n",
    "    * 主要问题：\n",
    "        * 1.构建一个深度学习网络并训练需要哪些步骤\n",
    "        * 2.什么时候该用parameter.data\n",
    "\n",
    "* [1.2 分类模型和softmax](#分类模型和softmax)\n",
    "    * 定义\n",
    "    * softmax的性质\n",
    "    * softmax的优势\n",
    "    * 分类模型\n",
    "    * 交叉熵函数\n",
    "\n",
    "* [1.3 多层感知机](#多层感知机)\n",
    "    * 定义\n",
    "    * 激活函数\n",
    "    * 主要问题：\n",
    "        * 如何选择不同激活函数\n",
    "\n",
    "* [1.4 模型选择（过拟合欠拟合的出现和解决)](#模型选择（过拟合欠拟合的出现和解决）)\n",
    "    * 模型选择的方法\n",
    "    * 欠拟合和过拟合定义和影响因素\n",
    "    * 欠拟合和过拟合的解决方法\n",
    "        * 权重衰减和正则化\n",
    "        * dropout\n",
    "\n",
    "* [1.5 数值稳定性与模型初始化](#数值稳定性与模型初始化)\n",
    "    * 梯度消失和梯度爆炸\n",
    "    * 导致梯度消失和爆炸的原因\n",
    "    * 神经原初始化\n",
    "\n",
    "2.卷积神经网络详解\n",
    "* [2.1 卷积神经网络](#卷积神经网络)\n",
    "    * 起源和特点\n",
    "    * 卷积神经网络组成\n",
    "    * 卷积层及其可选操作\n",
    "        *  空洞卷积  **todo**\n",
    "        *  感受野的计算  **todo**\n",
    "    * Pooling层\n",
    "    * 归一化层： \n",
    "        *  实例归一化 **todo**\n",
    "        *  批归一化 \n",
    "        *  组归一化 **todo**\n",
    "    * 损失函数  **todo**\n",
    "        *  交叉熵损失函数\n",
    "        *  L2损失\n",
    "        *  L1损失\n",
    "    * 卷积神经网络的整体结构\n",
    "    * 主要网络架构及其特点\n",
    "        * Lenet\n",
    "        * Alexnet\n",
    "        * VGG\n",
    "        * Network in Network（NIN）\n",
    "        * GoogLenet  \n",
    "        * Resnet  \n",
    "        * DenseNet\n",
    "\n",
    "* 3.循环神经网络  **todo**\n",
    "    * 基础\n",
    "    * GRU\n",
    "    * Lstm\n",
    "    * 深度循环神经网络\n",
    "    * 双向循环神经网络\n",
    "\n",
    "* 4.注意力机制  **todo**\n",
    "    * 基础\n",
    "    * Seq2seq中的应用\n",
    "\n",
    "* 5.Transformer  **todo**\n",
    "\n",
    "* [6.优化](#优化)\n",
    "    * 深度学习优化：\n",
    "        * 深度学习优化和普通优化的差异\n",
    "        * 基于梯度的优化方法的挑战\n",
    "    * 凸优化\n",
    "        * 凸性\n",
    "        * 凸函数的性质和 Jensen 不等式\n",
    "        * 如何优化带有限制条件的函数 \n",
    "    * 优化算法\n",
    "        * 牛顿法\n",
    "        * 共轭梯度法\n",
    "        * 随机梯度下降法\n",
    "        * 小批量随机梯度下降法 (SGD)\n",
    "    * 高阶优化算法\n",
    "        * momentum\n",
    "        * AdaGrad       \n",
    "        * RMSProp\n",
    "        * AdaDelta\n",
    "        * Adam\n",
    "\n",
    "* 7.数据增强  **todo**\n",
    "\n",
    "* 8.模型微调  **todo**\n",
    "\n",
    "* 9.GAN     **todo**\n",
    "    * basic\n",
    "    * DCGAN\n",
    "\n",
    "* 10.目标检测  **todo**\n",
    "\n",
    "* 11.语义分割  **todo**\n",
    "\n",
    "* 12.领域自适应  **todo**\n",
    "\n",
    "* 13.风格迁移  **todo**\n",
    "\n",
    "* 14.变化检测  **todo**"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}