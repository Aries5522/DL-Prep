{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 深度学习知识总结\n",
    "先从伯禹的学习资料入手，边学习，边 [整理记录](https://github.com/shiyutang/Hands-on-deep-learning) +《\n",
    "[神经网络和深度学习](https://nndl.github.io/nndl-book.pdf)\n",
    "》补充；\n",
    "累了可以听听 [MIT 的6.S191](https://www.youtube.com/watch?v=JN6H4rQvwgY) refresh一下\n",
    "\n",
    "根据下列框架进行结构性的知识总结。\n",
    "\n",
    "1.浅层神经网络及模型基础\n",
    "\n",
    "* [1.1 线性回归](#线性回归)\n",
    "    * 定义\n",
    "    * 实施步骤\n",
    "    * 要点\n",
    "    * 主要函数\n",
    "    * 主要问题：\n",
    "        * 1.构建一个深度学习网络并训练需要哪些步骤\n",
    "        * 2.什么时候该用parameter.data\n",
    "\n",
    "* [1.2 分类模型和softmax](#分类模型和softmax)\n",
    "    * 定义\n",
    "    * softmax的性质\n",
    "    * softmax的优势\n",
    "    * 分类模型\n",
    "    * 交叉熵函数\n",
    "\n",
    "* [1.3 多层感知机](#多层感知机)\n",
    "    * 定义\n",
    "    * 激活函数\n",
    "    * 主要问题：\n",
    "        * 如何选择不同激活函数\n",
    "\n",
    "* [1.4 模型选择（过拟合欠拟合的出现和解决)](#模型选择（过拟合欠拟合的出现和解决）)\n",
    "    * 模型选择的方法\n",
    "    * 欠拟合和过拟合定义和影响因素\n",
    "    * 欠拟合和过拟合的解决方法\n",
    "        * 权重衰减和正则化\n",
    "        * dropout\n",
    "\n",
    "* [1.5 数值稳定性与模型初始化](#数值稳定性与模型初始化)\n",
    "    * 梯度消失和梯度爆炸\n",
    "    * 导致梯度消失和爆炸的原因\n",
    "    * 神经原初始化\n",
    "\n",
    "2.卷积神经网络详解\n",
    "* [2.1 卷积神经网络](#卷积神经网络)\n",
    "    * 起源和特点\n",
    "    * 卷积神经网络组成\n",
    "    * 卷积层及其可选操作\n",
    "        *  空洞卷积  **todo**\n",
    "        *  感受野的计算  **todo**\n",
    "    * Pooling层\n",
    "    * 归一化层： **todo**\n",
    "        *  实例归一化\n",
    "        *  批归一化\n",
    "        *  组归一化\n",
    "    * 损失函数  **todo**\n",
    "        *  交叉熵损失函数\n",
    "        *  L2损失\n",
    "        *  L1损失\n",
    "    * 卷积神经网络的整体结构\n",
    "    * 主要网络架构及其特点\n",
    "        * Lenet\n",
    "        * Alexnet\n",
    "        * VGG\n",
    "        * Network in Network（NIN）\n",
    "        * GoogLenet  \n",
    "        * Resnet  \n",
    "        * DenseNet\n",
    "\n",
    "* 3.循环神经网络\n",
    "    * 基础\n",
    "    * GRU\n",
    "    * Lstm\n",
    "    * 深度循环神经网络\n",
    "    * 双向循环神经网络\n",
    "\n",
    "* 4.注意力机制\n",
    "    * 基础\n",
    "    * Seq2seq中的应用\n",
    "\n",
    "* 5.Transformer\n",
    "\n",
    "* 6.优化：\n",
    "    * 凸优化\n",
    "        * 基础：\n",
    "        * 自适应方法\n",
    "        * 牛顿法\n",
    "        * 共轭梯度法\n",
    "    * SGD\n",
    "        * momentum\n",
    "        * weight decay\n",
    "    * RMSProp\n",
    "    * Adam\n",
    "\n",
    "* 7.数据增强\n",
    "\n",
    "* 8.模型微调\n",
    "\n",
    "* 9.GAN\n",
    "    * basic\n",
    "    * DCGAN\n",
    "\n",
    "* 10.目标检测\n",
    "\n",
    "* 11.语义分割\n",
    "\n",
    "* 12.领域自适应\n",
    "\n",
    "* 13.风格迁移\n",
    "\n",
    "* 14.变化检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 线性回归\n",
    "\n",
    "__定义__：基于特征和标签之间的线性函数关系约束，线性回归通过建立单层神经网络，将神经网络中每一个神经元当成是函数关系中的一个参数，通过利用初始输出和目标输出建立损失，并优化损失最小的方式使得神经元的数值和真实函数参数数值最相近，从而通过网络训练得到最符合数据分布的函数关系。\n",
    "\n",
    "__实施步骤__：\n",
    "1. 初始通过随机化线性函数的参数，通过输入的x，会得到一系列y_h\n",
    "2. 输出的y_h和真实值y之间因为神经元参数不正确产生差距，为了y_h和y能尽量地逼近，我们通过平方误差损失函数（MSE Loss）来描述这种误差。\n",
    "3. 类似于通过求导得到损失函数最优解的方式，我们通过梯度下降法将这种误差传递到参数，通过调整参数使误差达到最小\n",
    "4. 通过几轮的训练，我们得到的最小的损失值对应的神经元数值，就是描述输入输出的线性关系的最好的参数。\n",
    "\n",
    "__要点__：\n",
    "1. 确定输入输出之间一定满足线性关系，这一点可以通过对x,y画图看出，只有线性关系才能使用线性回归训练得到\n",
    "2. 由于线性关系唯一由神经元个数决定，不同的参数个数唯一决定了这种线性关系，因此需要选择适合的特征用于线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 这一节中出现的有用的函数\n",
    "1. 使用plt绘制散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. 自行制作dataLoader: dataloader 为输入dataset可以随机获取dataset中batch size 个样本\n",
    "> 通过使用打乱的indices，每次yield batch size个样本，生成的生成器可以用for调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import  random\n",
    "\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)  # random read 10 samples\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        # the last time may be not enough for a whole batch\n",
    "        yield  features.index_select(0, j), labels.index_select(0, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 参数初始化：自行初始化网络中的参数，使用init模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net[0].weight, mean=0.0, std=0.01)\n",
    "init.constant_(net[0].bias, val=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要的问题：\n",
    "### 1.构建一个深度学习网络并训练需要哪些步骤？\n",
    "\n",
    "深度学习网络的主要组成部分就是数据，网络和训练，因此可以根据这三部分展开为下面几个步骤：\n",
    "\n",
    "0.数据部分\n",
    "1. 生成数据集/找到现有数据集\n",
    "2. 根据数据集构建Dataset 并用之构建dataloader\n",
    "3. （可选）调用构建的Dataloader，得到数据并可视化，检查实现的正确性，并对数据有一定了解\n",
    "\n",
    "1.网络部分\n",
    "4. 定义模型，初始化模型参数\n",
    "5. 定义损失函数，如本节的MSE loss\n",
    "6. 定义优化函数，SGD,Adam... 及其参数：学习率，动量，weight_decay...\n",
    "\n",
    "2.训练部分\n",
    "7. 使用循环的方式，每个循环训练一遍所有数据\n",
    "8. 将数据输入网络，根据损失函数和网络输出建立损失\n",
    "9. 梯度清零，损失回传，优化器更新损失\n",
    "10. 记录损失，可视化结果，往复训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.什么时候该用parameter.data?\n",
    "下面是课程中使用的优化器的代码，可以发现，参数的更新使用了param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # ues .data to operate param without gradient track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据我的理解，这是由于反向传播机制在需要更新的参数进行运算时会构建动态运算图，如果直接使用这个`param`进行更新，就会在动态图中计入这一部分，从而反向传播时也会将这一步运算的梯度加入。而我们实际希望的则是损失函数对参数进行求导，而不希望再此参数上“节外生枝”。因此，在网络前向传播和损失函数计算之外的参数运算，应当使用param.data进行更新\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类模型和softmax\n",
    "_定义_：softmax是用于将向量输出统一为有概率性质的一个函数，基于其指数的性质，它可以拉大大数和小数之间的差距，并且越大的数，为了达到和较小的数的差距只需要更小的差距，有助于筛选出一组向量中的最大值，并使其和其他数更加明显区分。\n",
    "\n",
    "_性质_: softmax函数的常数不变性，即 softmax(x)=softmax(x+c)：对需要进行softmax变换的向量，同时减去一个较大的数不会对结果产生影响，推导如下：\n",
    "\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "![alt text](Pics/softmax.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "优势：1. 通过softmax，输入向量每个元素的大小一目了然，不需要关心输出的具体数值，也不会存在输出相差较大时，不好比较的问题\n",
    "2. 使用softmax的输出进行交叉熵函数的比较相当于统一了量纲，平衡了不同输出结果的重要程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类模型\n",
    "_定义_：分类模型用于将输入的图片/信号进行分类，本单元讲到的分类模型是对输入进行一次线性变换，最后将分类结果利用softmax进行区分，示例如下图：\n",
    "\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "![Image Name](Pics/fc.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "_交叉熵函数_：上节的回归问题，我们用到了MSE，因为我们希望线性模型的参数和真实的完全一致，但是在分类模型中，我们只希望真实类别对应的概率越大越好，其他概率的具体数值对损失并没有过多含义。因此，这里使用了交叉熵函数，通过将标签化为one-hot编码，使得损失函数只关注正确类别对应的概率大小,其函数表达和实例操作如下：\n",
    "<div align=center>\n",
    "\n",
    "![Image Name](Pics/cross_ent.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "如果标签为one-hot编码且只有一个正确类别，那么最小化交叉熵损失就是最大化正确类别对应输出概率的log形式，从另一个角度来看，最小化交叉熵损失函数等价于最大化训练数据集所有标签类别的联合预测概率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 多层感知机\n",
    "_定义_：多层感知机是采用多个神经网络层，并在其中添加了非线性单元，从而使得网络可以得到从输入到输出的非线性映射，从而将线性模型转化为非线性模型，在此基础上，增加网络的深度可以进一步增加网络的复杂度。\n",
    "\n",
    "## 激活函数：\n",
    "_定义_：拥有非线性部分的函数，即函数的导数并非处处一致，常见的激活函数有Relu，Leaky-relu，tanh，sigmoid等\n",
    "\n",
    "实例：\n",
    "\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/activation.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "## 重要的问题：\n",
    "### 1. 不同的激活函数应当如何选择？\n",
    "在考虑不同激活函数的区别和优势时，我们主要考虑激活函数对神经元输出的影响和神经元的数值更新的能力。（即神经元的存在以及学习能力）\n",
    "\n",
    "*神经元的存在问题*：当一个神经元更新到无论什么参数输入，其输出均为零时，其就失活了。这个主要是因为某些激活函数的截断作用，当大量神经元失活，网络的复杂度就会受到严重影响\n",
    "\n",
    "*神经元参数的更新*：其取决于反向传播到该神经元的梯度值，这个梯度值是累乘的，其会乘上激活函数的梯度。因此，如果激活函数的梯度过小，那么就会导致这个神经元学习缓慢/无法学习\n",
    "\n",
    "\n",
    "* Relu：由于其计算效率和不容易梯度消失，从而大多数情况下使用；但是，由于其输出范围不确定，因此只能在隐藏层中使用；同时Relu函数因为在小于0的部分为0，因此容易在学习率大时使神经元失活\n",
    "\n",
    "* Sigmoid函数：用于分类器时，通常效果更好，但是存在由于梯度消失。\n",
    "\n",
    "* Tanh 函数: 和sigmoid 相似，但是其导数输出在（0，1），相比sigmoid更容易激活神经元；也存在梯度消失的问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 模型选择（过拟合欠拟合的出现和解决）\n",
    "我们在训练深度学习模型时，期望使用训练数据训练的这个模型能在测试数据上也能得到很好的表现，这个就是期望泛化误差减小。（_泛化误差:_ 模型在任意测试数据上的输出结果和真实结果的差距的期望，通常使用测试集上的误差来代表）\n",
    "\n",
    "为了得到这样一个模型，其中的主要影响因素是模型复杂度，输入数据量，训练时间，训练方法等。但是由于我们没有确切的方式定义这些因素是如何影响的，因此，我们需要各种各样的方法来选择模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型选择的方法\n",
    "选择模型时，我们主要参考两个指标。一个是训练误差，一个是验证误差，这里不能使用泛化误差是因为这样会导致泛化误差有偏，不能反映真实的泛化误差。\n",
    "训练误差和验证误差分别是模型在训练数据集和验证数据集上的误差，这个误差可以用交叉熵损失函数，MSE损失函数等多种损失函数计算得出\n",
    "* 验证数据集进行验证：\n",
    "验证集通过在整体数据中抽出一定比例数据组成，其不参与模型的训练过程，在模型使用训练数据训练完成后，我们通过其在验证集上的精度进行模型的选择。\n",
    "* k折验证法：\n",
    "有时，我们的数据不是非常充足，因此为了减少验证集对数据的浪费，我们采用K折验证法：\n",
    "   1. 我们将整个数据分成k份，其中（K-1）份代表训练集，1份代表验证集，同时我们要遍历所有的组合方式，也就生成K份不同的数据集\n",
    "   2. 模型分别基于K份数据集中的训练集进行训练，对应的验证集进行验证，获得的验证精度进行平均即获得这个模型的精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型的过拟合和欠拟合\n",
    "训练出来的模型一般存在两类问题，导致最终的验证结果不是最理想，因此我们需要尽量避免。\n",
    "<div align=center>\n",
    "\n",
    "![Image Name](Pics/OVERFIT.png)\n",
    "</div>\n",
    "\n",
    "_欠拟合_：训练误差无法达到较小，说明此时在训练数据上模型都不能正确拟合。\n",
    "_过拟合_：当训练误差已经较小，但是验证误差和训练误差相差较大，说明模型仅仅拟合到训练数据，该模型并不能泛化。\n",
    "\n",
    "影响欠拟合和过拟合的因素：\n",
    "影响模型有没有拟合/过拟合的因素是多方面的，包括模型模型复杂度，数据量，训练时间，训练方法等。\n",
    "* 模型复杂度：模型复杂度可以受到参数量，网络的广度深度的影响，其最终等效为这个模型能描述的所有的函数的集合。一个过大的模型在一定时间的训练下很容易过度拟合\n",
    "* 数据量： 数据量不仅仅是数据的多少，其还应该具有足够代表性和多样化。\n",
    "* 训练时间&训练方法：合适的训练方法和恰当的训练时间可以避免模型过拟合/欠拟合\n",
    "\n",
    "\n",
    "- 过拟合和欠拟合的解决方法\n",
    "为了解决过拟合/欠拟合，我们需要对模型的复杂度进行限制/增加更多的数据，下面提出两种解决过拟合的方法\n",
    "* 权重衰减和正则化：\n",
    "    在使用SGD优化方法时，正则化和权重衰减具有一致性。其中L2正则化是在模型的损失上添加一个权重的二范数作为惩罚项，从而限制参数的大小。\n",
    "    具体表达式以线性回归模型的损失函数为例：\n",
    "    <div align=center>\n",
    "\n",
    "    ![Untitled/Untitled.png](Pics/linearloss.png)\n",
    "\n",
    "    </div>\n",
    "\n",
    "    正则项则是参数的二范数:\n",
    "    <div align=center>\n",
    "\n",
    "    ![Untitled/Untitled.png](Pics/loss_reg.png)\n",
    "\n",
    "    </div>\n",
    "\n",
    "    最终，根据SGD的参数更新方式，我们可以得到如下更新公式：\n",
    "    <div align=center>\n",
    "\n",
    "    ![Untitled/Untitled.png](Pics/SGDupdate.png)\n",
    "\n",
    "    </div>\n",
    "\n",
    "    可以发现，添加了L2正则项的损失函数促使更新公式在权重项之前乘以了一个小于1的系数，也就是等效于权重衰减设置为lr*lambda\n",
    "\n",
    "* inverted dropout 丢弃法：\n",
    "\n",
    "   dropout的思想是在前向传播的时候，设置一概率p，使得每个神经元有p的概率输出为0，很明显，这样的方式可以达到网络稀疏化的效果，从而削弱了网络的表达能力，即复杂度。从而是一种有效的防止过拟合的方式，下面我们看看其具体是怎么运行的：\n",
    "\n",
    "    1. 在前向传播的时候，设置一个存在权重n，其有p的概率为0，1-p的概率为1，从而一个神经元输出为：\n",
    "\n",
    "       这里我们发现其输出的期望还是等于自身：\n",
    "\n",
    "       也就是增加了dropout的网络的输出平均值与没有增加dropout一致，而我们又知道dropout每次代表不同的网络结构，因此对增加了dropout的网络输出求平均即为对不同网络结构求平均，这样我们实现了一个网络结构和一次训练，但是求出的平均值等效于同时训练多个网络得到的平均值。这一种方法也有效地减少了过拟合。\n",
    "\n",
    "    2. 在训练过程中我们不断使用不同的数据重复上述步骤\n",
    "\n",
    "    3. 我们在测试是去除缩放因子，并对网络进行测试，由于第一步我们知道添加dropout与否的网络的平均值相同，那么我们在测试时去除缩放因子就保证了和训练的平均值相同。即我们测试了我们训练的网络。\n",
    "\n",
    "   那么dropout在网络结构层次上又是怎么影响的呢？\n",
    "   其作者认为，在训练神经网络时，过拟合现象起源于神经元之间的co-adpatation 相互适应，也就是某个神经元在给定某些固定特征时，其强行根据一些不正确的特征组合出最终的正确答案，因此dropout就打破了特征和输出的固定联系，从而促使网络根据一个更加general的场景做决定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 数值稳定性与模型初始化\n",
    "通常我们希望我们的模型在训练过程中能快速地学习并在学习之后收敛到一个较好的结果。因此网络的数值稳定性就格外重要，我们希望网络中的神经元能每次更新适当大小的梯度作为优化方向。而梯度消失和梯度爆炸则会导致上述训练停滞或不能收敛。\n",
    "> 深度模型有关数值稳定性的典型问题是衰减和爆炸。当神经网络的层数较多时，模型的数值稳定性容易变差。\n",
    "\n",
    "_梯度消失_：其指的是传递到很多神经元的梯度几乎为0，从而导致网络的学习停滞\n",
    "\n",
    "_梯度爆炸_：对应于梯度消失，梯度爆炸则代表神经元的梯度过大，使得其一下更新到一个不合适的位置，从而网络不能收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导致梯度消失和梯度爆炸的原因：\n",
    "1. 神经网络没有很好地初始化：当我们假设神经网络没有激活层时，传递到某一个神经元的梯度就是其后方连接上所有神经元参数的连乘积。那么，在较深的网络中如果我们将神经元均初始化较大（>1）的数值会导致梯度爆炸，较小（<1）则会导致梯度消失\n",
    "那么有激活函数的场景怎么样呢，有激活函数时，不同的损失函数的情况有所不同，对于Sigmoid激活函数，当参数初始化较小的值，神经元的输入会较小，此时激活函数对应的梯度也较小，由此影响到神经元的梯度也较小，从而造成了梯度消失。\n",
    "2. 没有选择恰当的激活函数：如第一点所述，不同的激活函数会对梯度消失和梯度爆炸产生影响，因此需要根据数据选择合理的激活函数\n",
    "3. 输入没有合理地归一化：影响激活函数梯度的除了其自身之外，还有其输入，即便神经元初始正常，没有归一化的输入也会导致神经元输出过大/小，从而激活函数梯度过小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经元初始化的方法--缓解梯度消失和爆炸\n",
    "根据上述阐述，我们知道神经元的权重应当初始化到一个1附近的数值/0附近（对于Sigmoid等激活函数来说），因此有各种各样的初始化方法，在pytorch里面可以通过torch.init调用\n",
    "Xavier初始化：将权重参数初始化到：\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/Uniform.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "根据均匀分布的均值和方差公式，我们可以知道其初始化后，均值为0，方差为2/（a+b）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络\n",
    "上面我们介绍的线性回归和多层感知机等均为全连接网络，但是全连接网络的两个缺点却对图片一类的数据很不友好：\n",
    "1. 参数量过大： 全连接层在处理输入（h1,w1,c1）输出（h2,w2,c2）时， 需要的参数量为h1\\*w1\\*c1\\*h2\\*w2\\*c2, 对于200\\*200\\*3大小的图片，单层的参数量就达到了14400000000。\n",
    "2. 没有办法识别空间局部特征，图片往往有空间相对信息，因此上下左右相邻的像素组合比展平的元素更有意义，同时缩放，平移，旋转不会改变这个区域的特征，但是全连接层则需要单独检测。\n",
    "\n",
    "为了解决上述问题，同时基于生物感受野的思想，卷积神经网络横空出世。\n",
    "在卷积神经网络中，影响输出元素 x 的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做 x 的感受野（receptive field）\n",
    "\n",
    "通过局部连接，权重共享，汇聚的结构，卷积神经网络解决了上述两个问题并不断发展，下面我们来讲述一下卷积神经网络的组成和技术细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络组成\n",
    "卷积神经网络主要有卷积层，池化层，归一化层，全连接层组成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层\n",
    "首先卷积层中最重要的就是卷积，但是实际上卷积层是做的互相关运算，而不是卷积运算。基于二者是旋转180度的关系，同时卷积层的参数是可学习的，因此我们可以直接使用互相关运算等效替代卷积运算并减少计算量。\n",
    "\n",
    "卷积运算公式：\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/conv.png)\n",
    "\n",
    "</div>\n",
    "互相关运算公式：\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/corr.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "在对图像做完卷积之后，我们还需要增加一个偏置b到最后的运算结果上，从而和之前的全连接层保持一致，记录与特征无关的平移，如下所示：\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/convmulc.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/convbias.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "卷积中的可选操作\n",
    "\n",
    "在卷积层中除了进行卷积的操作，还可以进行一些其他的操作保证更好地利用原图/特征图上的信息。\n",
    "* padding：为了保证原图/特征图的边缘也能多次参与和卷积核的运算并保证输入输出大小的不变性，人们采取将周边铺上0元素的方法，我们记单边增加了p列0元素。\n",
    "* 步长：是指卷积核在滑动时的时间间隔。有时图片的尺寸较大，而我们为了减少计算量，并尽可能多覆盖相同多的特征，就会采用带步长的卷积，我们记步长为s\n",
    "* 输入输出尺寸对应：设输入单边长度为lin，那么对应的输出单边长度为lout，而卷积核的单边长度为k\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/convsize.gif)\n",
    "\n",
    "</div>\n",
    "\n",
    "除此之外，还有空洞卷积，可变形卷积等其他卷积的变种可以用来进行卷积的操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling层\n",
    "汇聚层的作用是进行特征选择，降低特征数量，从而减少参数数量，同时可以对一些小的局部形态改变保持不变性，并拥有更大的感受野。但是过大的汇聚层会造成信息的损失。\n",
    "\n",
    "汇聚层的反向传播：和卷积层的反向传播不同，汇聚层的输入和输出不一致，因此，我们反向传播时需要考虑怎样将误差值从输出传播到输入。\n",
    "\n",
    "如果下采样是最大汇聚，误差项 𝛿(𝑙+1,𝑝) 中每个值会直接传递到上一层对应区域中的最大值所对应的神经元，该区域中其他神经元的误差项都设为0．如果下采样是平均汇聚，误差项𝛿(𝑙+1,𝑝) 中每个值会被平均分配到上一层对应区域中的所有神经元上\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/poolgrad.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化层\n",
    "通常，为了统一输入数据的量纲，我们会将输入数据进行归一化，从而可以避免量纲这种无关条件对神经网络学习的影响。\n",
    "但是光对输入进行归一化是不够的，在神经网络学习过程中，内部每一层输出也会不断发生变化，如果限制变化范围，就会使得后层神经层需要不断适应浅层神经层的输出，从而带来训练不稳定和训练速度慢的问题。为了解决这个问题，我们在神经网络的输出之后引入各种类型的归一化操作。\n",
    "\n",
    "**归一化层的作用就是通过规范每一层神经网络输出的分布，限制前层输出分布变化带来的后层输入的不稳定，从而引起的链式反应。**\n",
    "\n",
    "#### 批归一化层\n",
    "我们通常认为卷积层输出某一个通道代表了一类特征，因此批归一化通过将一个通道的所有特征图，使用样本统计量进行归一化并再一次进行仿射变换，获得变换后输出。也就是说，对于（N, C, H, W）的输入，其均值和方差的形状均为（1, C, 1, 1）。批量归一化主要有以下优势：\n",
    "\n",
    "    1. 在使用sigmoid/tanh激活函数时，限制神经元的输出范围，使得输出落在激活函数梯度较大的区域，避免梯度消失的情况，同样可以减少梯度爆炸的情况\n",
    "    2. 在深层网络中限制浅层神经网络输出的变化范围，避免深层神经元对变化大的浅层神经元输出的不断适应导致的训练不稳定问题\n",
    "    4. 起到正则化的效果，因为限制输出的范围，从而将输出空间大大减小，\n",
    "\n",
    "\n",
    "其推导公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.对全连接层做批量归一化\n",
    "位置：全连接层中的仿射变换和激活函数之间。  \n",
    "**全连接：**  \n",
    "$$\n",
    "\\boldsymbol{x} = \\boldsymbol{W\\boldsymbol{u} + \\boldsymbol{b}} \\\\\n",
    " output =\\phi(\\boldsymbol{x})\n",
    " $$   \n",
    "\n",
    "\n",
    "**批量归一化：**\n",
    "$$ \n",
    "output=\\phi(\\text{BN}(\\boldsymbol{x}))$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{y}^{(i)} = \\text{BN}(\\boldsymbol{x}^{(i)})\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mu}_\\mathcal{B} \\leftarrow \\frac{1}{m}\\sum_{i = 1}^{m} \\boldsymbol{x}^{(i)},\n",
    "$$ \n",
    "$$\n",
    "\\boldsymbol{\\sigma}_\\mathcal{B}^2 \\leftarrow \\frac{1}{m} \\sum_{i=1}^{m}(\\boldsymbol{x}^{(i)} - \\boldsymbol{\\mu}_\\mathcal{B})^2,\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{x}}^{(i)} \\leftarrow \\frac{\\boldsymbol{x}^{(i)} - \\boldsymbol{\\mu}_\\mathcal{B}}{\\sqrt{\\boldsymbol{\\sigma}_\\mathcal{B}^2 + \\epsilon}},\n",
    "$$\n",
    "\n",
    "这⾥ϵ > 0是个很小的常数，保证分母大于0\n",
    "\n",
    "\n",
    "$$\n",
    "{\\boldsymbol{y}}^{(i)} \\leftarrow \\boldsymbol{\\gamma} \\odot\n",
    "\\hat{\\boldsymbol{x}}^{(i)} + \\boldsymbol{\\beta}.\n",
    "$$\n",
    "\n",
    "\n",
    "引入可学习参数：拉伸参数γ和偏移参数β。若$\\boldsymbol{\\gamma} = \\sqrt{\\boldsymbol{\\sigma}_\\mathcal{B}^2 + \\epsilon}$和$\\boldsymbol{\\beta} = \\boldsymbol{\\mu}_\\mathcal{B}$，批量归一化无效。\n",
    "\n",
    "### 2.对卷积层做批量归⼀化\n",
    "位置：卷积计算之后、应⽤激活函数之前。  \n",
    "如果卷积计算输出多个通道，我们需要对这些通道的输出分别做批量归一化，且每个通道都拥有独立的拉伸和偏移参数。\n",
    "计算：对单通道，batchsize=m,对该通道中m×w×h个元素同时做批量归一化,使用相同的均值和方差。\n",
    "\n",
    "### 3.预测时的批量归⼀化\n",
    "训练：以batch为单位,对每个batch计算均值和方差。  \n",
    "预测：用移动平均估算整个训练数据集的样本均值和方差作为测试时的均值和方差。\n",
    "\n",
    "### 从零实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import sys\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batch_norm(is_training, X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # 判断当前模式是训练模式还是预测模式\n",
    "    if not is_training:\n",
    "        # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # 使用全连接层的情况，计算特征维上的均值和方差\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。这里我们需要保持\n",
    "            # X的形状以便后面可以做广播运算\n",
    "            mean = X.mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "        # 训练模式下用当前的均值和方差做标准化\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # 更新移动平均的均值和方差\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    Y = gamma * X_hat + beta  # 拉伸和偏移\n",
    "    return Y, moving_mean, moving_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super(BatchNorm, self).__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features) #全连接层输出神经元\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)  #通道数\n",
    "        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成0和1\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # 不参与求梯度和迭代的变量，全在内存上初始化成0\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.zeros(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 如果X不在内存上，将moving_mean和moving_var复制到X所在显存上\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # 保存更新过的moving_mean和moving_var, Module实例的traning属性默认为true, 调用.eval()后设成false\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(self.training, \n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.9)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在Lenet中的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            BatchNorm(6, num_dims=4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            BatchNorm(16, num_dims=4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            d2l.FlattenLayer(),\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            BatchNorm(120, num_dims=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            BatchNorm(84, num_dims=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            d2l.FlattenLayer(),\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积神经网络的整体结构\n",
    "通过组合卷积层，汇聚层，全连接层，卷积层用来识别图像里的空间模式，之后池化层用来降低卷积层对位置的敏感性,最后全连接层对物体进行分类。我们就可以获得以下一般的卷积神经网络结构：\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/convstruct.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "不过网络结构并不是一成不变的，而是根据需要不断去修改其中卷积的操作，层级的安排等等。我们现在已经越来越少见到卷积神经网络中的全连接层了，汇聚层的比例也在不断减少。\n",
    "\n",
    "## 经典的卷积神经网络\n",
    "通过学习一些经典的神经网络，我们可以学习到其中设计网络的思想"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenet\n",
    "\n",
    "Lenet的网络结构也遵循了我们之前提到的（卷积+激活+池化）*N+全连接的公式。\n",
    "* 卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用 5×5 的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。\n",
    "* 全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。\n",
    "<div align=center>\n",
    "\n",
    "![Untitled/Untitled.png](Pics/lenet.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet\n",
    "相较于Lenet，Alexnet是一个更加现代的卷积神经网络，其使用更深的网络来提升网络的参数/表征空间，并用一些技巧来控制模型的复杂度。主要有以下特征：\n",
    "1. 8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。\n",
    "2. 将sigmoid激活函数改成了更加简单的ReLU激活函数。\n",
    "3. 用Dropout来控制全连接层的模型复杂度。\n",
    "4. 引入数据增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "![Image Name](Pics/ALEX.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "除此之外，Alexnet还使用全卷积的方式来减少显存的占用，以往，我们每生成一张输出特征图就需要使用和输入相同channels的卷积核进行卷积，在群卷积中，每次只需要使用输入channels/K的卷积核进行运算，并把最后结果concate起来，就能获得和原来相同大小的输出。\n",
    "群卷积有助于减小参数的数量，但是其限制了每个卷积核对于通道的访问，从而限制了特征的组合。下图阐述了群卷积的运行：\n",
    "<div align=center>\n",
    "\n",
    "![gconv.png](Pics/gconv.png)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            #由于使用CPU镜像，精简网络，若为GPU镜像可添加该层\n",
    "            #nn.Linear(4096, 4096),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG\n",
    "使用多个重复的模块进行叠加的网络结构。\n",
    "* Block:数个相同的填充为1、窗口形状为 3×3 的卷积层,接上一个步幅为2、窗口形状为 2×2 的最大池化层。\n",
    "* 卷积层保持输入的高和宽不变，而池化层则对其减半。\n",
    "<div align=center>\n",
    "\n",
    "![Image Name](Pics/VGG.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VGG11 的简单实现\n",
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels): #卷积层个数，输入通道数，输出通道数\n",
    "    blk = []\n",
    "    for i in range(num_convs):\n",
    "        if i == 0:\n",
    "            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.ReLU())\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 这里会使宽高减半\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "conv_arch = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))\n",
    "# 经过5个vgg_block, 宽高会减半5次, 变成 224/32 = 7\n",
    "fc_features = 512 * 7 * 7 # c * w * h\n",
    "fc_hidden_units = 4096 # 任意\n",
    "\n",
    "def vgg(conv_arch, fc_features, fc_hidden_units=4096):\n",
    "    net = nn.Sequential()\n",
    "    # 卷积层部分\n",
    "    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):\n",
    "        # 每经过一个vgg_block都会使宽高减半\n",
    "        net.add_module(\"vgg_block_\" + str(i+1), vgg_block(num_convs, in_channels, out_channels))\n",
    "    # 全连接层部分\n",
    "    net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(),\n",
    "                                 nn.Linear(fc_features, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, 10)\n",
    "                                ))\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = vgg(conv_arch, fc_features, fc_hidden_units)\n",
    "X = torch.rand(1, 1, 224, 224)\n",
    "\n",
    "# named_children获取一级子模块及其名字(named_modules会返回所有子模块,包括子模块的子模块)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络中的网络\n",
    "__LeNet、AlexNet和VGG__：先以由卷积层构成的模块充分抽取 空间特征，再以由全连接层构成的模块来输出分类结果。\n",
    "\n",
    "__NiN__：\n",
    "串联多个由卷积层和“全连接”层构成的小⽹络来构建⼀个深层⽹络。\n",
    "⽤了输出通道数等于标签类别数的NiN块，然后使⽤全局平均池化层对每个通道中所有元素求平均并直接⽤于分类。\n",
    "\n",
    "![Image Name](Pics/NIN.png)\n",
    "\n",
    "1×1卷积核作用:\n",
    "\n",
    "- 放缩通道数：通过控制卷积核的数量达到通道数的放缩。\n",
    "- 增加非线性。1×1卷积核的卷积过程相当于全连接层的计算过程，并且还加入了非线性激活函数，从而可以增加网络的非线性。\n",
    "- 充当全连接层的作用，减少卷积层到全连接层之间的显式数据转换（4维张量的flatten操作）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NIN 网络的简单实现\n",
    "\n",
    "def nin_block(in_channels, out_channels, kernel_size, stride, padding):\n",
    "    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU())\n",
    "    return blk\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, stride=4, padding=0),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, stride=1, padding=1),\n",
    "    GlobalAvgPool2d(), \n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小, 10)\n",
    "    d2l.FlattenLayer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 1, 224, 224)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogLenet\n",
    "通过串联卷积模块和 Inception 模块来搭建网络结构。\n",
    "\n",
    "\n",
    "__Inception 模块：__ \n",
    "- 采用多个不同分支来提取不同细粒度的特征，从左到右，提取的特征越来越抽象；\n",
    "- 同时，为了能使得最后的特征能够拼接，需要对不同的分支采用不同的 padding 等操作，保证输出的长和宽不变；\n",
    "- 其中为了减少计算参数，在中间两个分支都采用了 1\\*1 的卷积层来减少输出通道，从而减少卷积核的通道数。 \n",
    "- 最后，通过控制不同分支的输出通道数来控制生成的 Inception 模块的复杂度\n",
    "\n",
    "![googlenet.png](Pics/googlenet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1 - c4为每条线路里的层的输出通道数\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GoogLenet 的完整结构 \n",
    "![img](Pics/googlenet_full.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   d2l.GlobalAvgPool2d())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, \n",
    "                    d2l.FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, d2l.FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "X = torch.rand(1, 1, 96, 96)\n",
    "\n",
    "for blk in net.children(): \n",
    "    X = blk(X)\n",
    "    print('output shape: ', X.shape)\n",
    "\n",
    "#batchsize=128\n",
    "batch_size = 16\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet\n",
    "\n",
    "通常来说，深层神经网路的表示函数能包含浅层神经网络的所有表示函数，因此，我们希望能根据输入数据，在更多的可能性中寻找合适的映射函数。但是，在使用深层神经网络时，我们往往会遇到过拟合问题，即神经网络没有拟合数据的一般规律，而是拟合了这一组数据中的噪声，造成神经网络的泛化能力差。因此，为了解决能更好地应用深层网络，Resnet 提供了一种跳接的连接方式，其示意图如下：\n",
    "\n",
    "![img](Pics/residual.png)\n",
    "\n",
    "可以发现，其通过将输入恒等加入到输出，促使后层网络能直接获取输入的信息，变相说来，这种跳接给网络提供了一种选择: 是否需要采用这个新加入的神经层，其也就使得网络能根据输入数据在复杂和简单的网络结构中进行良好的切换，实验结构表明，使用了 Resnet 跳接的网络可以增加很多层而不容易产生过拟合。\n",
    "\n",
    "除此之外， Residual 模块提供了在恒等变化的基础上捕捉变化的能力，促使网络表达更加细腻。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):  \n",
    "    #可以设定输出通道数、是否使用额外的1x1卷积层来修改通道数以及卷积层的步幅。\n",
    "    # 由于 resnet 是将结果相加，因此输入输出的形状需要一致，因此我们还需要用1*1卷积来统一可能变化的通道数\n",
    "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return F.relu(Y + X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet模型\n",
    "- 卷积(64,7x7,3)  \n",
    "- 批量一体化  \n",
    "- 最大池化(3x3,2)  \n",
    "\n",
    "- 残差块x4 (通过步幅为2的残差块在每个模块之间减小高和宽)\n",
    "\n",
    "- 全局平均池化\n",
    "\n",
    "- 全连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n",
    "    if first_block:\n",
    "        assert in_channels == out_channels # 第一个模块的通道数同输入通道数一致\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
    "net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
    "net.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, 512, 1, 1)\n",
    "net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(512, 10))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((1, 1, 224, 224))\n",
    "for name, layer in net.named_children():\n",
    "    X = layer(X)\n",
    "    print(name, ' output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet\n",
    "densenet 通过将跳接之后的连接过程从相加修改为 concatenate，形成了一个更激进的密集连接机制：即互相连接所有的层，即每个层都会接受其前面所有层作为其额外的输入。这样一来，后层可以直接访问前面任意层特征图，促进了信息综合。\n",
    "\n",
    "![img](Pics/densenet.png)\n",
    "\n",
    "![img](Pics/densenetjump.png)\n",
    "\n",
    "具体说来，其优势如下：\n",
    "1. DenseNet提升了梯度的反向传播，使得网络更容易训练。由于每层可以直达最后的误差信号，实现了隐式的“deep supervision”；\n",
    "2. 参数更小且计算更高效，其采用较小的growth rate，实现每个层所独有的特征图是比较小的；同时采用过渡层也减少了参数\n",
    "3. 由于特征复用，最后的分类器使用了低级特征，最后决策也就有机会采用多个尺度的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Densenet的构成\n",
    "\n",
    "1. 稠密层：实现稠密连接和特征复用\n",
    "2. 过渡层：通过减少通道和2\\*2的平均池化减少输出特征图，进一步减少后续模型参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels):\n",
    "    blk = nn.Sequential(nn.BatchNorm2d(in_channels), \n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "    return blk\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, in_channels, out_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        net = []\n",
    "        for i in range(num_convs):\n",
    "            in_c = in_channels + i * out_channels\n",
    "            net.append(conv_block(in_c, out_channels))\n",
    "        self.net = nn.ModuleList(net)\n",
    "        self.out_channels = in_channels + num_convs * out_channels # 计算输出通道数\n",
    "\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            X = torch.cat((X, Y), dim=1)  # 在通道维上将输入和输出连结\n",
    "        return X\n",
    "\n",
    "def transition_block(in_channels, out_channels):\n",
    "blk = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels), \n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "return blk\n",
    "\n",
    "blk = transition_block(23, 10)\n",
    "blk(Y).shape # torch.Size([4, 10, 4, 4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-e4750ca9da19>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m net = nn.Sequential(\n\u001B[0m\u001B[0;32m      2\u001B[0m         \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv2d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkernel_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m7\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstride\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m         \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mBatchNorm2d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m         \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mReLU\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "num_channels, growth_rate = 64, 32  # num_channels为当前的通道数\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
    "\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    DB = DenseBlock(num_convs, num_channels, growth_rate)\n",
    "    net.add_module(\"DenseBlosk_%d\" % i, DB)\n",
    "    # 上一个稠密块的输出通道数\n",
    "    num_channels = DB.out_channels\n",
    "    # 在稠密块之间加入通道数减半的过渡层\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\n",
    "        net.add_module(\"transition_block_%d\" % i, transition_block(num_channels, num_channels // 2))\n",
    "        num_channels = num_channels // 2\n",
    "\n",
    "net.add_module(\"BN\", nn.BatchNorm2d(num_channels))\n",
    "net.add_module(\"relu\", nn.ReLU())\n",
    "net.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, num_channels, 1, 1)\n",
    "net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(num_channels, 10))) \n",
    "\n",
    "X = torch.rand((1, 1, 96, 96))\n",
    "for name, layer in net.named_children():\n",
    "    X = layer(X)\n",
    "    print(name, ' output shape:\\t', X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}